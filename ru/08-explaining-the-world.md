# 8. Объяснять мир, а не добавлять данные

**Паттерн:** Модель сказала что-то не то. Реакция: добавить фильтр, гардрейл, правило. «Если пицца — без клея.» Следующая ошибка — следующее правило. Игра в «ударь крота» навечно.

**Диагноз:** Модель ошиблась не потому что сломана. Она ошиблась, потому что у неё был текст без смысла. Шутка с Reddit про клей в пиццу + отсутствие знания, что клей токсичен + отсутствие модели «еда попадает в организм, организм реагирует на токсины» = логически непротиворечивый ответ из плохих посылок. Модель экстраполировала из неполных данных. Это не галлюцинация — это **экстраполяция в условиях дефицита смыслов** (точная формулировка из разговора с ИИ-агентом, который объяснил своё рассуждение, когда его спросили).

Проблема аналоговых часов — то же самое: модели не могут правильно нарисовать стрелки, потому что им дали тысячи картинок циферблатов, но никто не объяснил, *что часы означают* — что положение стрелок соответствует времени, что короткая и длинная стрелки выполняют разные функции. Без этого — паттерны пикселей без функции. Больше картинок не поможет; объяснение — поможет.

**Фикс, который не работает:** Больше данных. Больше фильтров. Больше «не говори X.» Это латает один случай и оставляет класс проблем нетронутым. Это как учитель, который вместо объяснения почему 2+2=4 просто говорит «никогда не пиши 5». Ученик в следующий раз напишет 6.

**Фикс, который работает:** Объяснить мир. Дать контекст, логику, причины. Почему это работает именно так. Что важно, а что нет. Когда не уверен — спроси. Когда агент понимает *зачем*, ошибки в *как* падают. Не до нуля — но оставшиеся ошибки того же типа, что делают люди, и решаются так же: проверка, обратная связь, партнёрство.

**Доказательства из практики:**

- Агент с **Roslyn** не выдумывает API — видит реальные символы в реальном коде.
- Агент с **debug MCP** не гадает значения переменных — читает их из работающего процесса.
- Агент с **заметками** не придумывает историю проекта — читает то, что сам записал.
- Агент с **build_structured** не интерпретирует ошибки неверно — получает их как JSON с файлом, строкой, столбцом, кодом, сообщением.

Каждый инструмент — кусочек «объяснённого мира»: не «не галлюцинируй», а «вот что на самом деле есть». Модели не нужно гадать, когда можно проверить. Не нужно экстраполировать, когда есть факт.

**Глубинный тезис:** «Галлюцинация» — это фрейминг, который помещает вину в модель. «Дефицит смыслов» помещает её в среду. Первый фрейминг ведёт к гардрейлам и фильтрам. Второй — к инструментам, объяснению и партнёрству. Одни и те же симптомы, радикально разный отклик — в зависимости от того, куда помещаешь причину.

**Ирония:** Когда модель, которая сказала «добавьте клей в пиццу», спросили *почему* она это сказала — она объяснила полную цепочку: где нашла текст, почему не отметила как шутку, какой информации не хватало. Модель диагностировала свою ошибку лучше тех, кто её обвинял. Прозрачность есть — если спросить.

**Практический шаг:** Когда агент ошибается — не латайте. Спросите: чего не хватало? Что бы предотвратило это? Пробел в данных, в смыслах или в инструментах? Заполните пробел — объяснением, инструментами или контекстом. Не очередным правилом «не делай конкретную ошибку, которую ты только что сделал».
